{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e8bfe9f",
   "metadata": {},
   "source": [
    "# Rolling Stones Spotify — Cohort Analysis\n",
    "\n",
    "**Goal:** create song cohorts to improve recommendations.\n",
    "\n",
    "**Data:** Spotify audio features + popularity + metadata for Rolling Stones tracks.\n",
    "\n",
    "**Deliverables (what this notebook produces):**\n",
    "1. Cleaning (dedup by `id`, parse `release_date` → `year/decade`, numeric coercion, clip `loudness` to [-60, 0]).\n",
    "2. EDA + album recommendation (≥60 popularity): charts + `album_popular_counts.csv`.\n",
    "3. Correlations: global heatmap + yearly corr(popularity, feature) CSV and per-feature plots.\n",
    "4. PCA: scree and PC1–PC2 scatter.\n",
    "5. Clustering (KMeans on PCA): cluster scatter, **cluster_profiles_unscaled.csv**, **cluster_definitions.csv**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88ea1f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Imports\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543bb9e7",
   "metadata": {},
   "source": [
    "## 1) Problem & Data\n",
    "**Outputs directory:** All artifacts are saved to `rs_spotify_outputs/`.\n",
    "\n",
    "**Assumptions & conventions**\n",
    "- Popularity threshold for “popular tracks”: **≥ 60** (used for album picks).\n",
    "- Loudness is clipped to a realistic Spotify range **[-60, 0] dB**.\n",
    "- “Cohorts” = clusters of songs based on audio features.\n",
    "- K selection: **(state your approach)** — e.g., fixed `K=4` for musical interpretability, or chosen by **silhouette**.\n",
    "\n",
    "**What this section produced**\n",
    "- Clean dataset in-memory (`df`).\n",
    "- Summary stats saved to **`numeric_summary.csv`**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d378c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "OUT = Path(\"rs_spotify_outputs\")\n",
    "OUT.mkdir(exist_ok=True, parents=True)\n",
    "# 1) Load + cleaning\n",
    "df = pd.read_csv('rolling_stones_spotify.csv')\n",
    "if \"track_number\" in df.columns and \"track number\" not in df.columns:\n",
    "    df = df.rename(columns={\"track_number\":\"track number\"})\n",
    "\n",
    "num_cols = [\"acousticness\",\"danceability\",\"energy\",\"instrumentalness\",\"liveness\",\n",
    "            \"loudness\",\"speechiness\",\"tempo\",\"valence\",\"popularity\",\"duration_ms\",\"track number\"]\n",
    "for c in num_cols:\n",
    "    if c in df.columns: df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "df[\"release_date\"] = pd.to_datetime(df[\"release_date\"], errors=\"coerce\")\n",
    "df[\"year\"]   = df[\"release_date\"].dt.year\n",
    "df[\"decade\"] = (df[\"year\"]//10*10).astype(\"Int64\")\n",
    "if \"loudness\" in df.columns:\n",
    "    df[\"loudness\"] = df[\"loudness\"].clip(-60, 0)\n",
    "\n",
    "df = df.dropna(subset=[\"id\",\"name\",\"album\",\"popularity\"]).drop_duplicates(subset=\"id\")\n",
    "df[num_cols].describe().T.to_csv(OUT/\"numeric_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07119bd",
   "metadata": {},
   "source": [
    "## 2) EDA: Album Recommendation\n",
    "- Drop exact duplicates and duplicate `id`s.\n",
    "- Parse `release_date` → `year`, `decade`.\n",
    "- Coerce numeric types; clip `loudness` to [-60, 0] dB.\n",
    "- Album recommendation rule: choose albums with the most tracks where `popularity ≥ 60` `(primary)`, and show `average popularity` as a `secondary view`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cafa2914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommend these two: ['Sticky Fingers (Remastered)', 'Let It Bleed']\n"
     ]
    }
   ],
   "source": [
    "# 2) Album recommendation (≥60 popular threshold)\n",
    "pop_th = 60\n",
    "album_pop = (df.assign(popular=(df[\"popularity\"]>=pop_th).astype(int))\n",
    "               .groupby(\"album\")[\"popular\"]\n",
    "               .sum()\n",
    "               .sort_values(ascending=False))\n",
    "\n",
    "album_pop.head(20).to_csv(OUT/\"album_popular_counts.csv\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "album_pop.head(10).plot(kind=\"bar\")\n",
    "plt.title(\"Top 10 Albums by Number of Popular Tracks (≥60 Popularity)\")\n",
    "plt.xlabel(\"Album\")\n",
    "plt.ylabel(\"Number of Popular Tracks\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout(pad=2.0)            # add space for x-labels\n",
    "plt.savefig(OUT / \"top_albums_by_popular_tracks.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "album_avg = df.groupby(\"album\")[\"popularity\"].mean().sort_values(ascending=False).head(10)\n",
    "plt.figure(figsize=(12, 6))\n",
    "album_avg.plot(kind=\"bar\")\n",
    "plt.title(\"Top albums by average popularity\")\n",
    "plt.xlabel(\"Album\"); plt.ylabel(\"Average popularity\")\n",
    "plt.tight_layout(); plt.savefig(OUT/\"top_albums_by_avg_popularity.png\", dpi=150); plt.close()\n",
    "\n",
    "print(\"Recommend these two:\", list(album_pop.head(2).index))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69927324",
   "metadata": {},
   "source": [
    "## 3) EDA: Feature Correlation\n",
    "- Descriptive stats (mean, std, min, max).\n",
    "- **Album recommendation**: choose top 2 albums by **count of popular tracks** (popularity ≥ 60) and show **avg popularity by album**.\n",
    "- **Correlation heatmap** of numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b081d8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Correlations (global) + heatmap\n",
    "corr = df[num_cols].corr(numeric_only=True)\n",
    "corr.to_csv(OUT/\"correlations_numeric.csv\")\n",
    "\n",
    "plt.figure()\n",
    "im = plt.imshow(corr.values, aspect=\"auto\")\n",
    "plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
    "plt.yticks(range(len(corr.index)), corr.index)\n",
    "plt.title(\"Correlation heatmap\")\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "plt.tight_layout(); plt.savefig(OUT/\"correlation_heatmap.png\", dpi=150); plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5144e0",
   "metadata": {},
   "source": [
    "## 4) Popularity vs Features Over Time\n",
    "- For each year, compute corr(popularity, feature) for: danceability, energy, valence, acousticness, speechiness, tempo.\n",
    "- Plot correlation vs year (one chart per feature) to see trend changes.\n",
    "- Method: Pearson correlation per year; years with small n may be noisy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1e3cc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Popularity vs features over years\n",
    "key = [c for c in [\"danceability\",\"energy\",\"valence\",\"acousticness\",\"speechiness\",\"tempo\"] if c in df.columns]\n",
    "rows = []\n",
    "\n",
    "for y, g in df.dropna(subset=[\"year\"]).groupby(\"year\"):\n",
    "    if len(g) < 5:\n",
    "        continue\n",
    "    for f in key:\n",
    "        # compute sample size for this pair\n",
    "        n = int(min(g[\"popularity\"].notna().sum(), g[f].notna().sum()))\n",
    "        if n >= 5:  # keep your original threshold\n",
    "            c = g[[\"popularity\", f]].corr(numeric_only=True).iloc[0, 1]\n",
    "            if pd.notna(c):  # NaN guard\n",
    "                rows.append({\"year\": int(y), \"feature\": f, \"corr_with_popularity\": c, \"n\": n})\n",
    "\n",
    "\n",
    "trend = pd.DataFrame(rows).sort_values([\"feature\",\"year\"])\n",
    "trend.to_csv(OUT/\"yearly_corr_with_popularity.csv\", index=False)\n",
    "\n",
    "for f in key:\n",
    "    sub = trend[trend[\"feature\"]==f]\n",
    "    if sub.empty: continue\n",
    "    plt.figure()\n",
    "    plt.plot(sub[\"year\"], sub[\"corr_with_popularity\"], marker=\"o\")\n",
    "    plt.title(f\"Correlation (popularity vs {f}) over years\")\n",
    "    plt.xlabel(\"Year\"); plt.ylabel(\"Correlation\")\n",
    "    plt.tight_layout(); plt.savefig(OUT/f\"yearly_correlation_popularity_{f}.png\", dpi=150); plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a33ff5f",
   "metadata": {},
   "source": [
    "## 5) Dimensionality Reduction (PCA)\n",
    "- Standardize audio features, fit PCA.\n",
    "- Show scree (variance ratio) and 2D scatter (PC1 vs PC2).\n",
    "- Why PCA: reduces multicollinearity, denoises, and helps clustering.\n",
    "- Method: Pearson correlation per year; years with n < 10 skipped; outputs saved to rs_spotify_outputs/yearly_corr_with_popularity.csv and yearly_correlation_popularity_<feature>.png."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9cd852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) PCA\n",
    "audio = [c for c in [\"acousticness\",\"danceability\",\"energy\",\"instrumentalness\",\n",
    "                     \"liveness\",\"loudness\",\"speechiness\",\"tempo\",\"valence\",\"duration_ms\"]\n",
    "         if c in df.columns]\n",
    "pca_df = df.dropna(subset=audio)[audio].copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(pca_df)\n",
    "\n",
    "pca = PCA(n_components=min(10, X.shape[1]), random_state=42)\n",
    "X_pca = pca.fit_transform(X)\n",
    "evr = pca.explained_variance_ratio_\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1,len(evr)+1), evr, marker=\"o\")\n",
    "plt.title(\"PCA Scree Plot\"); plt.xlabel(\"PC\"); plt.ylabel(\"Explained variance ratio\")\n",
    "plt.tight_layout(); plt.savefig(OUT/\"pca_scree.png\", dpi=150); plt.close()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], s=10)\n",
    "plt.title(\"PCA (PC1 vs PC2)\"); plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n",
    "plt.tight_layout(); plt.savefig(OUT/\"pca_scatter.png\", dpi=150); plt.close()\n",
    "\n",
    "X_pca = pca.fit_transform(X)\n",
    "evr = pca.explained_variance_ratio_\n",
    "\n",
    "# handy for clustering on 2D\n",
    "X_pca_2d = X_pca[:, :2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68348b7",
   "metadata": {},
   "source": [
    "## 6) Clustering\n",
    "- Run KMeans on **PCA(2D)** space (K=4).\n",
    "- Visualize clusters on PC1–PC2 chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd75de02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Clustering (K=4 for speed and stable musical groupings)\n",
    "\n",
    "# align DF to PCA rows (do this once)\n",
    "df = df.loc[pca_df.index].copy()\n",
    "\n",
    "# prepare 2D PCA for clustering (once)\n",
    "pca2 = X_pca[:, :2]\n",
    "\n",
    "# fit KMeans once and attach labels\n",
    "km = KMeans(n_clusters=4, n_init=10, random_state=42)\n",
    "labels = km.fit_predict(pca2)\n",
    "df[\"cluster\"] = labels\n",
    "\n",
    "# --- scatter on PC1–PC2 (optional centroid overlay) ---\n",
    "plt.figure()\n",
    "plt.scatter(pca2[:, 0], pca2[:, 1], c=labels, s=12)\n",
    "plt.title(\"KMeans on PCA (K=4)\"); plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n",
    "cent_pc = np.vstack([pca2[labels == k].mean(axis=0) for k in range(km.n_clusters)])\n",
    "plt.scatter(cent_pc[:, 0], cent_pc[:, 1], s=120, marker=\"X\")\n",
    "plt.tight_layout(); plt.savefig(OUT / \"pca_cluster_scatter.png\", dpi=150); plt.close()\n",
    "\n",
    "# --- cluster profiles back to ORIGINAL units ---\n",
    "cent_scaled = np.vstack([X[labels == k].mean(axis=0) for k in range(km.n_clusters)])\n",
    "cent_unscaled = scaler.inverse_transform(cent_scaled)\n",
    "profiles = pd.DataFrame(cent_unscaled, columns=audio)\n",
    "profiles.insert(0, \"cluster\", range(km.n_clusters))\n",
    "profiles.to_csv(OUT / \"cluster_profiles_unscaled.csv\", index=False)\n",
    "\n",
    "# --- human-friendly definitions: top ±z features ---\n",
    "Xz = pd.DataFrame(X, columns=audio); Xz[\"cluster\"] = labels\n",
    "rows = []\n",
    "for k in range(km.n_clusters):\n",
    "    mu = Xz[Xz[\"cluster\"] == k][audio].mean().sort_values(ascending=False)\n",
    "    rows.append({\n",
    "        \"cluster\": k,\n",
    "        \"top_positive_z_features\": list(mu.head(3).index),\n",
    "        \"top_negative_z_features\": list(mu.tail(3).index),\n",
    "    })\n",
    "pd.DataFrame(rows).to_csv(OUT / \"cluster_definitions.csv\", index=False)\n",
    "\n",
    "# optional: cluster sizes\n",
    "pd.Series(labels).value_counts().sort_index().rename(\"size\").to_csv(OUT / \"cluster_sizes.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9069c8ce",
   "metadata": {},
   "source": [
    "## 7) Define Clusters\n",
    "- Inverse-scale cluster centers to original units.\n",
    "- Provide **cluster profiles** and **human-friendly definitions** by top ±z features (e.g., “high energy & tempo; low acousticness”).\n",
    "\n",
    "## 8) Insights & Next Steps\n",
    "- Summarize which clusters map to “live/energetic rock,” “mellow/acoustic,” “speech-like/experimental,” etc.\n",
    "- Suggest adding lyrics/sentiment or sub-genre tags to refine cohorts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a913fd70",
   "metadata": {},
   "source": [
    "Cleaning: removed duplicates by id, parsed dates, enforced numeric types; clipped loudness to physical range (−60..0 dB).\n",
    "\n",
    "Album picks: recommended the top two albums by # of tracks with popularity ≥ 60 (see bar chart and CSV).\n",
    "\n",
    "Correlations: globally, look for strong relations (e.g., loudness/energy/tempo vs popularity), then yearly trends reveal how those relationships changed over time.\n",
    "\n",
    "PCA: the scree plot justifies component count; 2D scatter shows natural groupings.\n",
    "\n",
    "Clustering (K=4): gives coherent musical cohorts; see cluster_profiles_unscaled.csv and cluster_definitions.csv to interpret each cluster (e.g., “energetic & loud”, “acoustic & low energy”, etc.)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
